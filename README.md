# LearnSign-AI-Machine-Learning-Based-Gamified-Sign-Language-Learning-Platform
# LearnSign: Real-Time Sign Language Recognition Web App

A web-based application for real-time American Sign Language (ASL) gesture recognition using computer vision and deep learning. Built with Python, TensorFlow, MediaPipe.

![Demo Screenshot](demo.png) <!-- Optional: Replace with your actual image -->

---

## ğŸ”¥ Features

- âœ‹ Real-time hand gesture recognition
- ğŸ¯ Displays prediction with confidence-based color feedback
- ğŸ“ Generates captions from gestures (e.g., "Hello Nehul")
- ğŸ§  Trained deep learning model with class balancing
- ğŸŸ¢ Green for high confidence, ğŸ”´ Red otherwise
- ğŸ’¬ Space & Delete gesture support for sentence creation
- ğŸ¥ Webcam integration via browser
- ğŸ’¾ Screenshot & save functionality (optional)
- âœ¨ Fancy UI with animations and loading screen

---

## ğŸ§  Tech Stack

- **Frontend:** HTML5, CSS3, JavaScript
- **Backend:** Python, Flask
- **Model:** TensorFlow + MediaPipe
- **Tools:** OpenCV, NumPy, LabelEncoder

---

## ğŸš€ How to Run
1. Clone the repository
   - git clone https://github.com/your-username/LearnSign.git
   - cd LearnSign

2. Create a virtual environment
   - python -m venv .venv
   - source .venv/bin/activate  # On Windows: .venv\Scripts\activate

3. Install dependencies
   - pip install -r requirements.txt
  
4. Run the Sign Language Recognizer
   - recognizer.py

